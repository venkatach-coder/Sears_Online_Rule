from typing import Dict
from pyspark.sql import DataFrame
import dp_rules
from rule_templates import default_rules

def merge_func(df_dict: Dict[str, DataFrame]):
    df1 = df_dict['temp_rule_table_base'] \
        .join(df_dict['explore_exploit'].selectExpr('div_no','itm_no','price as ee_price'),
              on=['div_no', 'itm_no'], how='inner')
    return df1

def pre_rule(row):
    if row['blocked'] is not None:
        return False, 'Blocked flag'
    return True, 'EE ignore ad_plan flag'


def core_rule(row):
    if row['ee_price'] is not None:
        return row['ee_price'], 'High_WOC'

def uplift_rule(row):
    if row['core_rule_value'] is not None:
        return row['core_rule_value'], 'Ignore uplift '

def clean_output(df):
    return df.drop('ee_price')


def construct_rule(rule_level) -> dp_rules.DP_Rule:
    thisrule = dp_rules.DP_Rule(
        target_tbl_name='rule_table',
        rule_level=rule_level,
        rule_name='explore_expolit',
        if_exists='append',
        desc='explore_expolit'
    )
    thisrule.add_rule_layer(
        dp_rules.DP_func(
            merge_func,
            input_type='Dict',
            func_desc='Table Selection')
    )
    thisrule.add_rule_layer(
        thisrule.pre_rule_wrapper(pre_rule, 'Only consider block flag')
    )
    thisrule.add_rule_layer(
        thisrule.core_rule_wrapper(core_rule, 'Take ee price')
    )
    thisrule.add_rule_layer(
        thisrule.uplift_wrapper(uplift_rule, 'Ignore uplift')
    )
    thisrule.add_rule_layer(
        thisrule.post_rule_wrapper(default_rules.default_postrule, 'Default post_rule')
    )
    thisrule.add_rule_layer(
        dp_rules.DP_func(
            clean_output,
            func_desc='drop column ee_price'
        )
    )
    return thisrule